{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need: Dataset, Column Report, Row Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Excel file with column lists\n",
    "allCols_df = pd.read_excel(\n",
    "    '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/Group1Data_ColumnReport.xlsx'\n",
    ")\n",
    "\n",
    "indicator_to_source = dict(zip(allCols_df[\"Indicator\"], allCols_df[\"Source Table\"]))\n",
    "\n",
    "LifeExpCols_df = pd.read_excel(\n",
    "    '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/Group1Data_ColumnReport.xlsx',\n",
    "    sheet_name='Life Expectancy Columns'\n",
    ")\n",
    "UnemCols_df = pd.read_excel(\n",
    "    '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/Group1Data_ColumnReport.xlsx',\n",
    "    sheet_name='Unemployment Columns'\n",
    ")\n",
    "\n",
    "# Load main dataset\n",
    "dataset_df = pd.read_csv(\n",
    "    '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/Group1Dataset_LCU_removed(except_exchange_rate).csv'\n",
    ")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 1. Extract column lists from the Excel sheets\n",
    "# ---------------------------------------------------------\n",
    "life_exp_cols = LifeExpCols_df['Indicator'].tolist()\n",
    "unem_cols = UnemCols_df['Indicator'].tolist()\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 2. Retain only the columns that exist in the dataset\n",
    "# ---------------------------------------------------------\n",
    "valid_life_exp_cols = [col for col in life_exp_cols if col in dataset_df.columns]\n",
    "valid_unem_cols = [col for col in unem_cols if col in dataset_df.columns]\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 3. Define a helper function to ensure essential columns appear at the beginning\n",
    "# ---------------------------------------------------------\n",
    "def ensure_essential_columns_at_start(cols, df, essential_cols):\n",
    "    \"\"\"\n",
    "    Ensures that the essential columns (if they exist in the dataset)\n",
    "    are placed at the beginning of the columns list.\n",
    "    \"\"\"\n",
    "    # Only consider essential columns that exist in the dataset\n",
    "    valid_essentials = [col for col in essential_cols if col in df.columns]\n",
    "    # Remove any occurrence of the essential columns from the existing list\n",
    "    remaining = [col for col in cols if col not in valid_essentials]\n",
    "    # Return the new list with essential columns first\n",
    "    return valid_essentials + remaining\n",
    "\n",
    "# Define essential columns in the desired order\n",
    "essential_cols = ['CountryShortName', 'Year']\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 4. Update the column lists for each group so that essential columns are first\n",
    "# ---------------------------------------------------------\n",
    "final_life_exp_cols = ensure_essential_columns_at_start(valid_life_exp_cols, dataset_df, essential_cols)\n",
    "final_unem_cols = ensure_essential_columns_at_start(valid_unem_cols, dataset_df, essential_cols)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# 5. Filter the dataset using the final column lists\n",
    "# ---------------------------------------------------------\n",
    "life_exp_data = dataset_df[final_life_exp_cols]\n",
    "unem_data = dataset_df[final_unem_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Data Loading Functions\n",
    "# ---------------------------\n",
    "def load_dataset(dataset_path):\n",
    "    \"\"\"Load a CSV dataset.\"\"\"\n",
    "    return pd.read_csv(dataset_path)\n",
    "\n",
    "def load_excel_sheet(excel_path, sheet_name=None):\n",
    "    \"\"\"Load an Excel sheet (or the first sheet if sheet_name is None).\"\"\"\n",
    "    return pd.read_excel(excel_path, sheet_name=sheet_name)\n",
    "\n",
    "# ---------------------------\n",
    "# Filtering Functions\n",
    "# ---------------------------\n",
    "def get_valid_columns(df, columns):\n",
    "    \"\"\"Return the subset of columns that exist in the DataFrame.\"\"\"\n",
    "    return [col for col in columns if col in df.columns]\n",
    "\n",
    "def ensure_essential_columns_at_start(cols, df, essential_cols):\n",
    "    \"\"\"\n",
    "    Ensure that essential columns (if they exist in df)\n",
    "    are placed at the beginning of the list.\n",
    "    \"\"\"\n",
    "    valid_essentials = [col for col in essential_cols if col in df.columns]\n",
    "    remaining = [col for col in cols if col not in valid_essentials]\n",
    "    return valid_essentials + remaining\n",
    "\n",
    "def filter_dataset(df, columns, essential_cols=['CountryShortName', 'Year']):\n",
    "    \"\"\"\n",
    "    Filter the DataFrame to only include the valid columns from the provided list.\n",
    "    Essential columns will be moved to the beginning.\n",
    "    \"\"\"\n",
    "    valid_cols = get_valid_columns(df, columns)\n",
    "    final_cols = ensure_essential_columns_at_start(valid_cols, df, essential_cols)\n",
    "    return df[final_cols]\n",
    "\n",
    "# ---------------------------\n",
    "# Missing Data Report Functions\n",
    "# ---------------------------\n",
    "def create_missing_report_by_column_with_source(df, mapping):\n",
    "    \"\"\"\n",
    "    Create a DataFrame reporting the count and percentage of missing values for each column,\n",
    "    and add a column for the Source Table based on the mapping.\n",
    "    \"\"\"\n",
    "    # Create missing values report with column names as a column named \"Column\"\n",
    "    report = pd.DataFrame({\n",
    "        'missing_count': df.isna().sum(),\n",
    "        'missing_percent': df.isna().mean() * 100\n",
    "    }).reset_index().rename(columns={'index': 'Column'})\n",
    "    \n",
    "    # Add the Source Table column by mapping the \"Column\" names to the dictionary\n",
    "    report[\"Source Table\"] = report[\"Column\"].map(mapping)\n",
    "    return report\n",
    "\n",
    "# ---------------------------\n",
    "# Utility Functions\n",
    "# ---------------------------\n",
    "def save_csv(df, output_path, index=False):\n",
    "    \"\"\"Save a DataFrame to a CSV file.\"\"\"\n",
    "    df.to_csv(output_path, index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Main Workflow\n",
    "# ---------------------------\n",
    "# Define file paths\n",
    "excel_path = '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/Group1Data_ColumnReport.xlsx'\n",
    "dataset_path = '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/Group1Dataset_LCU_removed(except_exchange_rate).csv'\n",
    "\n",
    "# Load Excel sheets containing the column lists\n",
    "allCols_df = load_excel_sheet(excel_path)\n",
    "life_exp_cols_df = load_excel_sheet(excel_path, sheet_name='Life Expectancy Columns')\n",
    "unem_cols_df = load_excel_sheet(excel_path, sheet_name='Unemployment Columns')\n",
    "\n",
    "# Extract column lists from the Excel sheets\n",
    "life_exp_cols = life_exp_cols_df['Indicator'].tolist()\n",
    "unem_cols = unem_cols_df['Indicator'].tolist()\n",
    "\n",
    "# Load the main dataset\n",
    "dataset_df = load_dataset(dataset_path)\n",
    "\n",
    "# Filter datasets using the lists (ensuring CountryShortName and Year are first)\n",
    "life_exp_data = filter_dataset(dataset_df, life_exp_cols)\n",
    "unem_data = filter_dataset(dataset_df, unem_cols)\n",
    "\n",
    "# Generate missing reports for Life Expectancy data\n",
    "life_exp_missing_report = create_missing_report_by_column_with_source(life_exp_data, indicator_to_source)\n",
    "\n",
    "# Generate missing reports for Unemployment data\n",
    "unem_missing_report = create_missing_report_by_column_with_source(unem_data, indicator_to_source)\n",
    "\n",
    "# Save the filtered datasets to CSV files\n",
    "save_csv(life_exp_data, '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/LifeExpectancyDataset.csv')\n",
    "save_csv(unem_data, '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/UnemploymentDataset.csv')\n",
    "\n",
    "# Save the missing reports for Life Expectancy data\n",
    "save_csv(life_exp_missing_report, '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/LifeExp_MissingReport.csv')\n",
    "\n",
    "# Save the missing reports for Unemployment data\n",
    "save_csv(unem_missing_report, '/Users/josh/Desktop/Macbook Working Files/Git Repos/culminating-project-group-1/Week 5/Datasets and Research Questions/JC/Unem_MissingReport.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

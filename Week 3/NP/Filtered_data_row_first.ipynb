{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "817a364c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "\n",
    "# -------------------------------\n",
    "# Function: Iteratively Remove Columns/Rows with High Missing Values\n",
    "# -------------------------------\n",
    "def iterative_filter(df, col_thresh=50, row_thresh=30, max_iter=5):\n",
    "    \"\"\" Iteratively removes columns and rows exceeding missing value thresholds. \"\"\"\n",
    "    iteration = 0\n",
    "    while iteration < max_iter:\n",
    "        iteration += 1\n",
    "        prev_shape = df.shape\n",
    "        \n",
    "                \n",
    "        # Drop rows with more than row_thresh% missing values\n",
    "        df = df.loc[df.isnull().mean(axis=1) * 100 < row_thresh, :]\n",
    "        \n",
    "        \n",
    "        # Drop columns with more than col_thresh% missing values\n",
    "        df = df.loc[:, df.isnull().mean() * 100 < col_thresh]\n",
    "\n",
    "\n",
    "        print(f\"Iteration {iteration}: Reduced from {prev_shape} → {df.shape}\")\n",
    "        \n",
    "        # Stop if no more changes\n",
    "        if df.shape == prev_shape:\n",
    "            break\n",
    "    return df\n",
    "\n",
    "# -------------------------------\n",
    "# Function: Load Country Metadata from SQLite\n",
    "# -------------------------------\n",
    "def load_country_meta(db_path, income_group=None, region=None):\n",
    "    \"\"\" Loads country metadata and filters based on income group and/or region. \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    query = \"SELECT [Short Name], [Income Group], Region FROM Country\"\n",
    "    \n",
    "    filters = []\n",
    "    if income_group:\n",
    "        filters.append(f\"[Income Group] = '{income_group}'\")\n",
    "    if region:\n",
    "        filters.append(f\"Region = '{region}'\")\n",
    "    \n",
    "    if filters:\n",
    "        query += \" WHERE \" + \" AND \".join(filters)\n",
    "\n",
    "    df_country = pd.read_sql_query(query, conn)\n",
    "    conn.close()\n",
    "    return df_country\n",
    "\n",
    "# -------------------------------\n",
    "# Function: Load and Filter CSV Data Based on Selected Countries\n",
    "# -------------------------------\n",
    "def load_and_filter_csv(csv_path, country_list):\n",
    "    \"\"\" Loads CSV data and filters by selected countries. \"\"\"\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"Initial CSV shape:\", df.shape)\n",
    "\n",
    "    # Keep only rows for selected countries\n",
    "    df = df[df['CountryShortName'].isin(country_list)]\n",
    "\n",
    "    # Apply iterative missing value filtering\n",
    "    df_filtered = iterative_filter(df.copy())\n",
    "\n",
    "    print(\"Filtered CSV shape:\", df_filtered.shape)\n",
    "    return df_filtered\n",
    "\n",
    "# -------------------------------\n",
    "# Function: Build Indicator Mapping from SQLite\n",
    "# -------------------------------\n",
    "def build_indicator_mapping(db_path):\n",
    "    \"\"\" Extracts indicator-to-table mapping from all indicator tables in SQLite. \"\"\"\n",
    "    conn = sqlite3.connect(db_path)\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Get all indicator tables dynamically\n",
    "    cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table' AND name LIKE '%Indicator%'\")\n",
    "    indicator_tables = [row[0] for row in cursor.fetchall()]\n",
    "\n",
    "    indicator_mapping = {}\n",
    "    for table in indicator_tables:\n",
    "        col_name = \"Series Name\" if \"QPSD\" in table else \"Indicator Name\"\n",
    "        query = f\"SELECT [{col_name}] FROM [{table}]\"\n",
    "        \n",
    "        try:\n",
    "            df_temp = pd.read_sql(query, conn)\n",
    "            for indicator in df_temp[col_name].dropna():\n",
    "                indicator_mapping[indicator] = table\n",
    "        except Exception as e:\n",
    "            print(f\"Skipping table {table} due to error: {e}\")\n",
    "    \n",
    "    conn.close()\n",
    "    return indicator_mapping\n",
    "\n",
    "# -------------------------------\n",
    "# Function: Compute Missing Data by Country\n",
    "# -------------------------------\n",
    "def compute_missing_by_country(df):\n",
    "    \"\"\" Aggregates missing values at the country level. \"\"\"\n",
    "    missing_info = df.groupby(\"CountryShortName\").apply(\n",
    "        lambda group: pd.Series({\n",
    "            \"missing_count\": group.isnull().sum().sum(),\n",
    "            \"missing_percentage\": (group.isnull().sum().sum() / (group.shape[0] * group.shape[1])) * 100\n",
    "        }),\n",
    "        include_groups=False\n",
    "    ).reset_index()\n",
    "    \n",
    "    return missing_info.sort_values(\"missing_percentage\", ascending=False)\n",
    "\n",
    "# -------------------------------\n",
    "# Main Processing Function\n",
    "# -------------------------------\n",
    "def main(csv_path, db_path, income_group=None, region=None):\n",
    "    \"\"\" Runs the full process: Load, filter, clean, and generate reports. \"\"\"\n",
    "    \n",
    "    # Step 1: Load country metadata with optional filters\n",
    "    df_country = load_country_meta(db_path, income_group, region)\n",
    "    print(\"Country metadata shape:\", df_country.shape)\n",
    "\n",
    "    # Step 2: Filter CSV based on country selection\n",
    "    selected_countries = df_country['Short Name'].tolist()\n",
    "    df_filtered = load_and_filter_csv(csv_path, selected_countries)\n",
    "\n",
    "    # Step 3: Extract indicator-to-table mapping\n",
    "    indicator_mapping = build_indicator_mapping(db_path)\n",
    "\n",
    "    # Step 4: Compute missing values by country\n",
    "    missing_by_country = compute_missing_by_country(df_filtered)\n",
    "\n",
    "    # Step 5: Merge missing count with country metadata\n",
    "    df_final = missing_by_country.merge(df_country, left_on=\"CountryShortName\", right_on=\"Short Name\", how=\"left\")\n",
    "    df_final = df_final.drop(columns=[\"Short Name\"]).sort_values(\"missing_count\", ascending=False)\n",
    "\n",
    "    print(\"\\nFinal Merged Report (Missing Values with Income Group and Region):\")\n",
    "    print(df_final)\n",
    "\n",
    "    return df_filtered, df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f219ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country metadata shape: (85, 3)\n",
      "Initial CSV shape: (5380, 1764)\n",
      "Iteration 1: Reduced from (1742, 1764) → (7, 1278)\n",
      "Iteration 2: Reduced from (7, 1278) → (7, 1278)\n",
      "Filtered CSV shape: (7, 1278)\n",
      "\n",
      "Final Merged Report (Missing Values with Income Group and Region):\n",
      "  CountryShortName  missing_count  missing_percentage Income Group  \\\n",
      "1            Korea          214.0            2.793004  High income   \n",
      "0  Slovak Republic           85.0            6.656226  High income   \n",
      "\n",
      "                  Region  \n",
      "1    East Asia & Pacific  \n",
      "0  Europe & Central Asia  \n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# Run the Main Processing Function\n",
    "# -------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    CSV_PATH = r\"C:\\Users\\Namrata Patil\\Desktop\\bana698-project\\culminating-project-group-1\\Week 3\\NP\\Group1Data.csv\"   \n",
    "    DB_PATH = r\"C:\\Users\\Namrata Patil\\Desktop\\bana698-project\\culminating-project-group-1\\Week 2\\Database Files\\BANA698GROUP1.db.db\"\n",
    "    # Set income group or region for filtering (set to None if you want all)\n",
    "    SELECTED_INCOME_GROUP = \"High income\" \n",
    "    SELECTED_REGION = None\n",
    "\n",
    "    df_filtered, df_final_report = main(\n",
    "        CSV_PATH, DB_PATH,\n",
    "        income_group=SELECTED_INCOME_GROUP,\n",
    "        region=SELECTED_REGION\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc7803",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered.to_csv(\"df_filtered_row_first.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6d2dd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
